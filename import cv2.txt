import cv2
import mediapipe as mp
import pyautogui
import time

# Initialize webcam and face mesh
cam = cv2.VideoCapture(0)
if not cam.isOpened():
    print("Error: Could not open webcam.")
    exit()

face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)

# Get screen width and height
screen_w, screen_h = pyautogui.size()

# Define sensitivity and margins for mouse movement
MARGIN = 1  # Reduced margin for full screen usage
BASE_SENSITIVITY = 2.5  # Base sensitivity factor for mouse movement
EAR_THRESHOLD = 0.1  # Eye Aspect Ratio threshold for blink detection

# Click timing variables
left_click_time = 0
right_click_time = 0
click_delay = 0.2  # Delay to prevent multiple clicks

# Helper function for calculating vertical distance
def vertical_distance(landmark1, landmark2):
    return abs(landmark1.y - landmark2.y)

# Helper function to calculate Eye Aspect Ratio (EAR)
def eye_aspect_ratio(eye_landmarks):
    A = vertical_distance(eye_landmarks[1], eye_landmarks[5])
    B = vertical_distance(eye_landmarks[2], eye_landmarks[4])
    C = vertical_distance(eye_landmarks[0], eye_landmarks[3])
    return (A + B) / (2.0 * C)

# Smoothing function for mouse movement
def smooth_move(current_pos, target_pos, smoothing_factor=0.3):
    return current_pos + (target_pos - current_pos) * smoothing_factor

# Initialize mouse position
mouse_x, mouse_y = screen_w // 2, screen_h // 2

while True:
    success, frame = cam.read()
    if not success:
        break

    frame = cv2.flip(frame, 1)  # Mirror the frame horizontally
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    output = face_mesh.process(rgb_frame)
    landmark_points = output.multi_face_landmarks
    frame_h, frame_w, _ = frame.shape

    if landmark_points:
        landmarks = landmark_points[0].landmark

        # Control mouse pointer with face position (nose landmark)
        nose_landmark = landmarks[1]  # Nose tip
        norm_x = (nose_landmark.x - 0.5) * 2  # Normalize to range [-1, 1]
        norm_y = (nose_landmark.y - 0.5) * 2

        # Calculate screen position
        target_x = screen_w / 2 + (screen_w / 2) * norm_x * BASE_SENSITIVITY
        target_y = screen_h / 2 + (screen_h / 2) * norm_y * BASE_SENSITIVITY

        # Apply margin to avoid corners
        target_x = max(min(target_x, screen_w - MARGIN), MARGIN)
        target_y = max(min(target_y, screen_h - MARGIN), MARGIN)

        # Smooth mouse movement
        mouse_x = smooth_move(mouse_x, target_x)
        mouse_y = smooth_move(mouse_y, target_y)

        pyautogui.moveTo(mouse_x, mouse_y)

        # Detect blink and click using eye aspect ratio
        left_eye = [landmarks[145], landmarks[159]]  # Landmarks for left eye
        right_eye = [landmarks[374], landmarks[386]]  # Landmarks for right eye

        # Check if the left eye is closed for left click
        if (left_eye[0].y - left_eye[1].y) < 0.004:
            pyautogui.click(button='left')
            time.sleep(click_delay)  # Prevent multiple clicks

        # Check if the right eye is closed for right click
        if (right_eye[0].y - right_eye[1].y) < 0.004:
            pyautogui.click(button='right')
            time.sleep(click_delay)

    # Show the frame
    cv2.imshow('Eye Controlled Mouse', frame)

    # Exit condition for ESC key
    if cv2.waitKey(1) & 0xFF == 27:  # Exit on ESC key
        break

# Release resources
cam.release()
cv2.destroyAllWindows()